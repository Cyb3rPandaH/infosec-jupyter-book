{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with Spark.SQL: Filtering & Summarizing\n",
    "* **Author**: Jose Rodriguez (@Cyb3rPandah)\n",
    "* **Project**: Infosec Jupyter Book\n",
    "* **Public Organization**: [Open Threat Research](https://github.com/OTRF)\n",
    "* **License**: [Creative Commons Attribution-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-sa/4.0/)\n",
    "* **Reference**: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating SQL view from Mordor APT29 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark_Data_Analysis\") \\\n",
    "    .config(\"spark.sql.caseSensitive\",\"True\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expose the dataframe as a SQL view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apt29Json = 'datasets/apt29_evals_day1_manual_2020-05-01225525.json'\n",
    "\n",
    "apt29Df = spark.read.json(apt29Json)\n",
    "\n",
    "apt29Df.createOrReplaceTempView('apt29')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering & Summarizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Sysmon event 8 (Create Remote Thread) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataframe has 95 records!!\n",
      "+---------------------------------------------------------+-------------------------------+-------------+\n",
      "|SourceImage                                              |TargetImage                    |StartFunction|\n",
      "+---------------------------------------------------------+-------------------------------+-------------+\n",
      "|C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe|C:\\Windows\\System32\\lsass.exe  |-            |\n",
      "|C:\\Windows\\System32\\csrss.exe                            |C:\\Windows\\System32\\svchost.exe|CtrlRoutine  |\n",
      "|C:\\Windows\\System32\\csrss.exe                            |C:\\Windows\\System32\\svchost.exe|CtrlRoutine  |\n",
      "|C:\\Windows\\System32\\csrss.exe                            |C:\\Windows\\System32\\svchost.exe|CtrlRoutine  |\n",
      "|C:\\Windows\\System32\\csrss.exe                            |C:\\Windows\\System32\\svchost.exe|CtrlRoutine  |\n",
      "+---------------------------------------------------------+-------------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sysmon8 = spark.sql(\n",
    "'''\n",
    "SELECT SourceImage, TargetImage, StartFunction\n",
    "FROM apt29\n",
    "WHERE Channel = 'Microsoft-Windows-Sysmon/Operational' AND EventID = 8\n",
    "''')\n",
    "\n",
    "print('This dataframe has {} records!!'.format(sysmon8.count()))\n",
    "sysmon8.show(n = 5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter PowerShell processes within Sysmon event 8 (Create Remote Thread) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataframe has 1 records!!\n",
      "+---------------------------------------------------------+-----------------------------+-------------+\n",
      "|SourceImage                                              |TargetImage                  |StartFunction|\n",
      "+---------------------------------------------------------+-----------------------------+-------------+\n",
      "|C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe|C:\\Windows\\System32\\lsass.exe|-            |\n",
      "+---------------------------------------------------------+-----------------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sysmon8 = spark.sql(\n",
    "'''\n",
    "SELECT SourceImage, TargetImage, StartFunction\n",
    "FROM apt29\n",
    "WHERE Channel = 'Microsoft-Windows-Sysmon/Operational'\n",
    "    AND EventID = 8\n",
    "    AND SourceImage LIKE '%powershell.exe%'\n",
    "''')\n",
    "\n",
    "print('This dataframe has {} records!!'.format(sysmon8.count()))\n",
    "sysmon8.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARIZING data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack Count event logs by source of data and event id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataframe has 203 records!!\n",
      "+----------------------------------------+-------+--------+\n",
      "|Channel                                 |EventID|count(1)|\n",
      "+----------------------------------------+-------+--------+\n",
      "|Microsoft-Windows-Sysmon/Operational    |12     |61151   |\n",
      "|Microsoft-Windows-Sysmon/Operational    |10     |39283   |\n",
      "|Microsoft-Windows-Sysmon/Operational    |7      |20259   |\n",
      "|Microsoft-Windows-Sysmon/Operational    |13     |17541   |\n",
      "|Security                                |4658   |8561    |\n",
      "|Windows PowerShell                      |800    |5113    |\n",
      "|Microsoft-Windows-PowerShell/Operational|4103   |5080    |\n",
      "|Security                                |4690   |4269    |\n",
      "|Security                                |4656   |4260    |\n",
      "|Security                                |4663   |4197    |\n",
      "|Security                                |5156   |2679    |\n",
      "|security                                |5447   |2579    |\n",
      "|security                                |4658   |2412    |\n",
      "|Microsoft-Windows-Sysmon/Operational    |11     |1649    |\n",
      "|Security                                |5158   |1465    |\n",
      "|security                                |4656   |1237    |\n",
      "|Microsoft-Windows-Sysmon/Operational    |3      |1229    |\n",
      "|security                                |4690   |1202    |\n",
      "|security                                |4663   |1140    |\n",
      "|Security                                |4703   |902     |\n",
      "+----------------------------------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eventLogs = spark.sql(\n",
    "'''\n",
    "SELECT Channel, EventID, COUNT(*)\n",
    "FROM apt29\n",
    "GROUP BY Channel, EventID\n",
    "ORDER BY COUNT(*) DESC\n",
    "''')\n",
    "\n",
    "print('This dataframe has {} records!!'.format(eventLogs.count()))\n",
    "eventLogs.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering event logs groups with frequency less or equal to 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataframe has 180 records!!\n",
      "+----------------------------------------+-------+-----+\n",
      "|Channel                                 |EventID|Count|\n",
      "+----------------------------------------+-------+-----+\n",
      "|security                                |5156   |484  |\n",
      "|Microsoft-Windows-Sysmon/Operational    |1      |447  |\n",
      "|security                                |5158   |431  |\n",
      "|Microsoft-Windows-Sysmon/Operational    |23     |422  |\n",
      "|Microsoft-Windows-PowerShell/Operational|4104   |414  |\n",
      "|security                                |4673   |409  |\n",
      "|Microsoft-Windows-Sysmon/Operational    |5      |401  |\n",
      "|Microsoft-Windows-Sysmon/Operational    |18     |362  |\n",
      "|security                                |5154   |362  |\n",
      "|security                                |4688   |279  |\n",
      "|Security                                |4689   |238  |\n",
      "|Security                                |4627   |234  |\n",
      "|Security                                |4624   |234  |\n",
      "|Security                                |4634   |233  |\n",
      "|Microsoft-Windows-Sysmon/Operational    |2      |209  |\n",
      "|Security                                |4688   |181  |\n",
      "|security                                |4945   |176  |\n",
      "|security                                |4689   |160  |\n",
      "|Security                                |4672   |154  |\n",
      "|Windows PowerShell                      |600    |138  |\n",
      "+----------------------------------------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eventLogsLess = spark.sql(\n",
    "'''\n",
    "SELECT Channel, EventID, COUNT(*) as Count\n",
    "FROM apt29\n",
    "GROUP BY Channel, EventID\n",
    "HAVING Count <= 500\n",
    "ORDER BY Count DESC\n",
    "''')\n",
    "\n",
    "print('This dataframe has {} records!!'.format(eventLogsLess.count()))\n",
    "eventLogsLess.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you! I hope you enjoyed it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark_Python3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}